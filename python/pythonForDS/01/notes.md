## Python for Data Science

Prototyping :

## Building a data pipeline :

	Creating  a pipeline allows you to work with the data. When the dataset

	gets to a certain size, you will be working on it from disk. It is 

	important to understanding the technique to implement to access the 

	data. This technique will impact how fast you get a result.


## Performing the required shaping :

	The shape of the data is the way it is presented and its characteristics 

	such data type. This is important when performing analysis. Data should

	be shaped the same, like comparing apples to apples. You will also need to 

	shape the data to conform to the algorithms needed to utilize/analyze the

	data. 


## Analyzing the data :

	When analyzing data, the use of a single algorithm is not usual. Which 

	algo would be the best fit? Which algo would produce the best results

	from the dataset. Experiment with the several algorithms to find the 

	best optimized algo.


## Presenting a result :

    Use data visualization to present data as graphs ..etc Also recommended to

    create multiple representations.


# Speed of Execution :

	Factors that control the speed of execution of a data science application :

**Dataset Size** Data Science relies on huge datasets in many cases. A robot for
example could use a dataset to recognize physical objects. FOr business analysis, larger datasets are preferable, and also the size of the **source data** The application type determines the size of your dataset in part, but dataset size also relies on the size of the source data. **Underestimating the effect of dataset size is deadly in data science apps. Think of self driving cars.**

# Loading Technique : 

Always use the fastest method available. Working with memory is faster than disk(duh!) Accessing local data is always faster than accessing over network. The Internet is the slowest for processing data.

# Coding style :
 
 efficient use of Python code. 

# Machine capability : 

**good hardware**

# Analysis algorithm : 

 The algo used determines the kind of result which can be obtained and controls the execution of speed. You must experiment to find the best algo.

**speed and reliability**

I/O Read/Write operation speeds in databases. 


## SciPy for scientific tools 


Python libs that provide support for mathematics, engineering, general science.

	* NumPy

	* SciPy

	* matplotlib

	* Sympy

	* pandas

SciPy lib focuses on numerical routines, such as routines for numerical integration and optimization. SciPy is general-purpose library. Providing support for domain-specific libraries, such as Scikit-image and statsmodels.


## NumPy used for performing fundamental scientific computing 

The NumPy lib provides the means for performing n-dimensional array manipulation, which is critical for data science work. **NumPy includes to support linear Algebra, Fourier transform, and random-number generation**

## Using Pandas for data analysis

Pandas provide support for data structures and data analysis tools. The lib is optimized to perform data science tasks especially fast and efficiently. The principle behind pandas is to provide data analysis and modeling support for Python that is similar as R.

## Scikit-learn for implementing machine learning 

Scikit-learn lib builds on the capabilities provided by NumPy and SciPy to allow Python developers to perform domain-specific tasks. **The lib focuses on data mining and data analysis. it provides access to the following sorts of functionality** :

**Classification**

**Regression** 

**Clustering**

**Dimensionality reduction**

**Model selection**

**Preprocessing**

    Beautiful soup good for HTML/XML parsing

Pythonxy alternative to intelliJ





